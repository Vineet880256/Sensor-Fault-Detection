[ 2022-11-04 21:36:01,610 ] 19 root - INFO - Main Starting
[ 2022-11-04 21:36:01,611 ] 21 root - INFO - Entered the start_data_ingestion method of TrainPipeline class
[ 2022-11-04 21:36:01,611 ] 25 root - INFO - Getting the data from mongodb
[ 2022-11-04 21:36:01,611 ] 112 root - INFO - Entered initiate_data_ingestion method of Data_Ingestion class
[ 2022-11-04 21:36:01,612 ] 31 root - INFO - Exporting data from mongodb
[ 2022-11-04 21:36:01,792 ] 20 root - INFO - Connection is successfully done
[ 2022-11-04 21:36:48,443 ] 39 root - INFO - Shape of dataframe: (35001, 171)
[ 2022-11-04 21:36:48,463 ] 47 root - INFO - Saving exported data into feature store file path: artifact\11_04_2022_21_35_55\data_ingestion\feature_store\sensor.csv
[ 2022-11-04 21:36:54,494 ] 121 root - INFO - Got the data from mongodb
[ 2022-11-04 21:36:54,494 ] 69 root - INFO - Entered split_data_as_train_test method of Data_Ingestion class
[ 2022-11-04 21:36:54,843 ] 76 root - INFO - Performed train test split on the dataframe
[ 2022-11-04 21:36:54,843 ] 78 root - INFO - Exited split_data_as_train_test method of Data_Ingestion class
[ 2022-11-04 21:36:54,844 ] 86 root - INFO - Exporting train and test file path.
[ 2022-11-04 21:37:00,669 ] 96 root - INFO - Exported train and test file path.
[ 2022-11-04 21:37:00,939 ] 125 root - INFO - Performed train test split on the dataset
[ 2022-11-04 21:37:00,939 ] 127 root - INFO - Exited initiate_data_ingestion method of Data_Ingestion class
[ 2022-11-04 21:37:00,939 ] 136 root - INFO - Data ingestion artifact: DataIngestionArtifact(trained_file_path='artifact\\11_04_2022_21_35_55\\data_ingestion\\ingested\\train.csv', test_file_path='artifact\\11_04_2022_21_35_55\\data_ingestion\\ingested\\test.csv')
[ 2022-11-04 21:37:01,646 ] 33 root - INFO - Got the train_set and test_set from mongodb
[ 2022-11-04 21:37:01,646 ] 35 root - INFO - Exited the start_data_ingestion method of TrainPipeline class
[ 2022-11-04 21:37:01,648 ] 48 root - INFO - Entered the start_data_validation method of TrainPipeline class
[ 2022-11-04 21:37:01,745 ] 130 root - INFO - Starting data validation
[ 2022-11-04 21:37:03,227 ] 39 root - INFO - Is required column present: [True]
[ 2022-11-04 21:37:03,227 ] 142 root - INFO - All required columns present in training dataframe: True
[ 2022-11-04 21:37:03,227 ] 39 root - INFO - Is required column present: [True]
[ 2022-11-04 21:37:03,228 ] 151 root - INFO - All required columns present in testing dataframe: True
[ 2022-11-04 21:37:03,228 ] 65 root - INFO - Missing numerical column: []
[ 2022-11-04 21:37:03,229 ] 65 root - INFO - Missing numerical column: []
[ 2022-11-04 21:37:08,116 ] 107 root - INFO - 0/164 drift detected.
[ 2022-11-04 21:37:08,118 ] 190 root - INFO - Data validation artifact: DataValidationArtifact(validation_status=True, valid_train_file_path='artifact\\11_04_2022_21_35_55\\data_ingestion\\ingested\\train.csv', valid_test_file_path='artifact\\11_04_2022_21_35_55\\data_ingestion\\ingested\\test.csv', invalid_train_file_path='artifact\\11_04_2022_21_35_55\\data_validation\\invalid\\train.csv', invalid_test_file_path='artifact\\11_04_2022_21_35_55\\data_validation\\invalid\\test.csv', drift_report_file_path='artifact\\11_04_2022_21_35_55\\data_validation\\drift_report\\report.yaml')
[ 2022-11-04 21:37:08,124 ] 58 root - INFO - Performed the data validation operation
[ 2022-11-04 21:37:08,125 ] 60 root - INFO - Exited the start_data_validation method of TrainPipeline class
[ 2022-11-04 21:37:08,125 ] 84 root - INFO - Starting data transformation
[ 2022-11-04 21:37:08,125 ] 54 root - INFO - Entered get_data_transformer_object method of DataTransformation class
[ 2022-11-04 21:37:08,125 ] 59 root - INFO - Got numerical cols from schema config
[ 2022-11-04 21:37:08,127 ] 65 root - INFO - Initialized RobustScaler, Simple Imputer
[ 2022-11-04 21:37:08,128 ] 71 root - INFO - Created preprocessor object from ColumnTransformer
[ 2022-11-04 21:37:08,128 ] 73 root - INFO - Exited get_data_transformer_object method of DataTransformation class
[ 2022-11-04 21:37:08,128 ] 88 root - INFO - Got the preprocessor object
[ 2022-11-04 21:37:09,123 ] 106 root - INFO - Got train features and test features of Training dataset
[ 2022-11-04 21:37:09,131 ] 116 root - INFO - Got train features and test features of Testing dataset
[ 2022-11-04 21:37:09,131 ] 118 root - INFO - Applying preprocessing object on training dataframe and testing dataframe
[ 2022-11-04 21:37:09,601 ] 124 root - INFO - Used the preprocessor object to fit transform the train features
[ 2022-11-04 21:37:09,643 ] 130 root - INFO - Used the preprocessor object to transform the test features
[ 2022-11-04 21:37:09,645 ] 132 root - INFO - Applying SMOTETomek on Training dataset
[ 2022-11-04 21:38:19,832 ] 140 root - INFO - Applied SMOTETomek on training dataset
[ 2022-11-04 21:38:19,832 ] 142 root - INFO - Applying SMOTETomek on testing dataset
[ 2022-11-04 21:38:23,487 ] 148 root - INFO - Applied SMOTETomek on testing dataset
[ 2022-11-04 21:38:23,487 ] 150 root - INFO - Created train array and test array
[ 2022-11-04 21:38:23,529 ] 60 root - INFO - Entered the save_object method of MainUtils class
[ 2022-11-04 21:38:23,558 ] 64 root - INFO - Exited the save_object method of MainUtils class
[ 2022-11-04 21:38:25,898 ] 175 root - INFO - Saved the preprocessor object
[ 2022-11-04 21:38:25,899 ] 177 root - INFO - Exited initiate_data_transformation method of Data_Transformation class
